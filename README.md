## Task 01 - Text Generation with GPT-2

This project explores text generation using the GPT-2 language model. Given an input prompt, the model generates coherent and context-aware text using sampling techniques like top-k and top-p. Ideal for learning how large language models generate human-like text.
